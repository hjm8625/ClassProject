# -*- coding: utf-8 -*-
"""simpleFFT_LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ypfaQ280pU-1K9_CIfoJZtz1a5lCIb12
"""

import os
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

freqss=[]
magnitudess=[]
labels = []

# base path of files
base_path = '/content'

for i in range(1,61):
    folder_name = f'{i:02d}'
    audio_folder=os.path.join(base_path, folder_name)
    if i==60:
        print('FINISH!')

    for file_name in os.listdir(audio_folder):
        if file_name.endswith('.wav'):
            # file path
            file_path = os.path.join(audio_folder, file_name)

            # 16k sampling
            audio, sr = librosa.load(file_path, sr=16000)

            # using FFT
            fft_result = np.fft.fft(audio)
            magnitude = np.abs(fft_result)
            freqs = np.fft.fftfreq(len(magnitude), d=1/sr)

            # using only positive parts
            positive_freq_indices = freqs > 0
            freq=freqs[positive_freq_indices]
            magnitude=magnitude[positive_freq_indices]

            # padding
            if len(freq)<3000:
                freq = np.pad(freq,(0,3000-len(freq)), 'constant',constant_values=0)
            if len(magnitude)<3000:
                magnitude = np.pad(magnitude,(0,3000-len(magnitude)), 'constant',constant_values=0)

            freq=freq[0:3000]
            magnitude=magnitude[0:3000]

            freqss.append([freq])
            magnitudess.append([magnitude])


            label = int(file_name.split('_')[0])
            labels.append(label)

freqss=np.array(freqss)
magnitudess=np.array(magnitudess)
labels = np.array(labels,dtype=int)

table = np.concatenate((freqss,magnitudess),axis=1)

table.shape

labels.shape

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = table
y = labels


y_one_hot = to_categorical(y, num_classes=10)

X_train, X_val, y_train, y_val = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)

model = Sequential([
    LSTM(128, input_shape=(2, 3000), return_sequences=False),
    Dropout(0.3),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)

print("Training complete. Final validation accuracy:", history.history['val_accuracy'][-1])

import librosa
import numpy as np
import matplotlib.pyplot as plt

# base path
base_path = "/content/01"
file_template = "{num}_01_1.wav"

for i in range(0, 10):
    # audio_path
    audio_path = f"{base_path}/{file_template.format(num=i)}"

    # 16k sampling
    audio, sr = librosa.load(audio_path, sr=16000)

    # FFT result
    fft_result = np.fft.fft(audio)  # using numpy fft
    magnitude = np.abs(fft_result)  # obtain Magnitude
    freqs = np.fft.fftfreq(len(magnitude), d=1/sr)  # obtain frequency

    # using only positive parts
    positive_freq_indices = freqs > 0
    magnitude = magnitude[positive_freq_indices]
    freqs = freqs[positive_freq_indices]


    # Plot the values(magnitude, frequency)
    plt.figure(figsize=(6, 3))
    plt.plot(freqs, magnitude, color='black')
    plt.title(f"FFT of the Audio Signal {i}")
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Magnitude")
    plt.grid()
    plt.tight_layout()
    plt.show()

print(magnitude[:10])
print(freqs[:10])

